{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\PC\\.cache\\kagglehub\\datasets\\yudhaislamisulistya\\plants-type-datasets\\versions\\16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['split_ttv_dataset_type_of_plants']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "import torchsummary\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yudhaislamisulistya/plants-type-datasets\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "import os\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test_Set_Folder', 'Train_Set_Folder', 'Validation_Set_Folder']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = os.path.join(path,\"split_ttv_dataset_type_of_plants\")\n",
    "os.listdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(ROOT_PATH,\"Train_Set_Folder\")\n",
    "test_dir = os.path.join(ROOT_PATH,\"Test_Set_Folder\")\n",
    "val_dir = os.path.join(ROOT_PATH,\"Validation_Set_Folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(300,300)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageFolder(root=train_dir,transform=transform)\n",
    "test_data = ImageFolder(root=test_dir,transform=transform)\n",
    "val_data = ImageFolder(root=val_dir,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size=32,shuffle=False)\n",
    "val_dataloader = DataLoader(val_data,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  \n",
    "\n",
    "def train_step(model, train_loader, loss_fn, optimizer, device):\n",
    "    model.train()  \n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = loss_fn(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def val_step(model, val_loader, loss_fn, device):\n",
    "    model.eval()  \n",
    "    val_loss, val_acc = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # Gradient hesaplama kapalı\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += (preds == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MobileNetV2Transfer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Training: 100%|██████████| 750/750 [01:32<00:00,  8.10it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 0.9953, Train Acc: 0.7171\n",
      "Val Loss: 0.5778, Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.92it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "Train Loss: 0.6102, Train Acc: 0.8086\n",
      "Val Loss: 0.4634, Val Acc: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:33<00:00,  8.03it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "Train Loss: 0.5361, Train Acc: 0.8271\n",
      "Val Loss: 0.4218, Val Acc: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.94it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "Train Loss: 0.4938, Train Acc: 0.8366\n",
      "Val Loss: 0.3907, Val Acc: 0.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:33<00:00,  8.02it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "Train Loss: 0.4617, Train Acc: 0.8474\n",
      "Val Loss: 0.3722, Val Acc: 0.8802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:35<00:00,  7.86it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "Train Loss: 0.4609, Train Acc: 0.8467\n",
      "Val Loss: 0.3780, Val Acc: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:36<00:00,  7.77it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:12<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "Train Loss: 0.4494, Train Acc: 0.8505\n",
      "Val Loss: 0.3616, Val Acc: 0.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.96it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "Train Loss: 0.4324, Train Acc: 0.8569\n",
      "Val Loss: 0.3382, Val Acc: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.92it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "Train Loss: 0.4343, Train Acc: 0.8549\n",
      "Val Loss: 0.3705, Val Acc: 0.8792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:36<00:00,  7.79it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:12<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "Train Loss: 0.4196, Train Acc: 0.8606\n",
      "Val Loss: 0.3331, Val Acc: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.91it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "Train Loss: 0.4249, Train Acc: 0.8552\n",
      "Val Loss: 0.3392, Val Acc: 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:34<00:00,  7.90it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Train Loss: 0.4192, Train Acc: 0.8605\n",
      "Val Loss: 0.3193, Val Acc: 0.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:35<00:00,  7.86it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "Train Loss: 0.4080, Train Acc: 0.8645\n",
      "Val Loss: 0.3155, Val Acc: 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:32<00:00,  8.15it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "Train Loss: 0.4142, Train Acc: 0.8640\n",
      "Val Loss: 0.3149, Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 750/750 [01:36<00:00,  7.78it/s]\n",
      "Validating: 100%|██████████| 95/95 [00:11<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "Train Loss: 0.3996, Train Acc: 0.8682\n",
      "Val Loss: 0.3163, Val Acc: 0.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_mobile = MobileNetV2Transfer(num_classes=30).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_mobile.parameters(), lr=0.001)\n",
    "EPOCHS = 15\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_step(model_mobile, train_dataloader, loss_fn, optimizer, device)\n",
    "    val_loss, val_acc = val_step(model_mobile, val_dataloader, loss_fn, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 94/94 [00:11<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8925950633755837 0.35376690347936557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_mobile.eval()  \n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "with torch.no_grad():  # Gradient hesaplama kapalı\n",
    "    for images, labels in tqdm(test_dataloader, desc=\"Validating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model_mobile(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_acc += (preds == labels).sum().item()\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_dataloader)\n",
    "test_acc /= len(test_dataloader.dataset)\n",
    "print(test_acc,test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 150, 150]             864\n",
      "       BatchNorm2d-2         [-1, 32, 150, 150]              64\n",
      "             ReLU6-3         [-1, 32, 150, 150]               0\n",
      "            Conv2d-4         [-1, 32, 150, 150]             288\n",
      "       BatchNorm2d-5         [-1, 32, 150, 150]              64\n",
      "             ReLU6-6         [-1, 32, 150, 150]               0\n",
      "            Conv2d-7         [-1, 16, 150, 150]             512\n",
      "       BatchNorm2d-8         [-1, 16, 150, 150]              32\n",
      "  InvertedResidual-9         [-1, 16, 150, 150]               0\n",
      "           Conv2d-10         [-1, 96, 150, 150]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 150, 150]             192\n",
      "            ReLU6-12         [-1, 96, 150, 150]               0\n",
      "           Conv2d-13           [-1, 96, 75, 75]             864\n",
      "      BatchNorm2d-14           [-1, 96, 75, 75]             192\n",
      "            ReLU6-15           [-1, 96, 75, 75]               0\n",
      "           Conv2d-16           [-1, 24, 75, 75]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 75, 75]              48\n",
      " InvertedResidual-18           [-1, 24, 75, 75]               0\n",
      "           Conv2d-19          [-1, 144, 75, 75]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 75, 75]             288\n",
      "            ReLU6-21          [-1, 144, 75, 75]               0\n",
      "           Conv2d-22          [-1, 144, 75, 75]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 75, 75]             288\n",
      "            ReLU6-24          [-1, 144, 75, 75]               0\n",
      "           Conv2d-25           [-1, 24, 75, 75]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 75, 75]              48\n",
      " InvertedResidual-27           [-1, 24, 75, 75]               0\n",
      "           Conv2d-28          [-1, 144, 75, 75]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 75, 75]             288\n",
      "            ReLU6-30          [-1, 144, 75, 75]               0\n",
      "           Conv2d-31          [-1, 144, 38, 38]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 38, 38]             288\n",
      "            ReLU6-33          [-1, 144, 38, 38]               0\n",
      "           Conv2d-34           [-1, 32, 38, 38]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 38, 38]              64\n",
      " InvertedResidual-36           [-1, 32, 38, 38]               0\n",
      "           Conv2d-37          [-1, 192, 38, 38]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 38, 38]             384\n",
      "            ReLU6-39          [-1, 192, 38, 38]               0\n",
      "           Conv2d-40          [-1, 192, 38, 38]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 38, 38]             384\n",
      "            ReLU6-42          [-1, 192, 38, 38]               0\n",
      "           Conv2d-43           [-1, 32, 38, 38]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 38, 38]              64\n",
      " InvertedResidual-45           [-1, 32, 38, 38]               0\n",
      "           Conv2d-46          [-1, 192, 38, 38]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 38, 38]             384\n",
      "            ReLU6-48          [-1, 192, 38, 38]               0\n",
      "           Conv2d-49          [-1, 192, 38, 38]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 38, 38]             384\n",
      "            ReLU6-51          [-1, 192, 38, 38]               0\n",
      "           Conv2d-52           [-1, 32, 38, 38]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 38, 38]              64\n",
      " InvertedResidual-54           [-1, 32, 38, 38]               0\n",
      "           Conv2d-55          [-1, 192, 38, 38]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 38, 38]             384\n",
      "            ReLU6-57          [-1, 192, 38, 38]               0\n",
      "           Conv2d-58          [-1, 192, 19, 19]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 19, 19]             384\n",
      "            ReLU6-60          [-1, 192, 19, 19]               0\n",
      "           Conv2d-61           [-1, 64, 19, 19]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 19, 19]             128\n",
      " InvertedResidual-63           [-1, 64, 19, 19]               0\n",
      "           Conv2d-64          [-1, 384, 19, 19]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 19, 19]             768\n",
      "            ReLU6-66          [-1, 384, 19, 19]               0\n",
      "           Conv2d-67          [-1, 384, 19, 19]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 19, 19]             768\n",
      "            ReLU6-69          [-1, 384, 19, 19]               0\n",
      "           Conv2d-70           [-1, 64, 19, 19]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 19, 19]             128\n",
      " InvertedResidual-72           [-1, 64, 19, 19]               0\n",
      "           Conv2d-73          [-1, 384, 19, 19]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 19, 19]             768\n",
      "            ReLU6-75          [-1, 384, 19, 19]               0\n",
      "           Conv2d-76          [-1, 384, 19, 19]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 19, 19]             768\n",
      "            ReLU6-78          [-1, 384, 19, 19]               0\n",
      "           Conv2d-79           [-1, 64, 19, 19]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 19, 19]             128\n",
      " InvertedResidual-81           [-1, 64, 19, 19]               0\n",
      "           Conv2d-82          [-1, 384, 19, 19]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 19, 19]             768\n",
      "            ReLU6-84          [-1, 384, 19, 19]               0\n",
      "           Conv2d-85          [-1, 384, 19, 19]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 19, 19]             768\n",
      "            ReLU6-87          [-1, 384, 19, 19]               0\n",
      "           Conv2d-88           [-1, 64, 19, 19]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 19, 19]             128\n",
      " InvertedResidual-90           [-1, 64, 19, 19]               0\n",
      "           Conv2d-91          [-1, 384, 19, 19]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 19, 19]             768\n",
      "            ReLU6-93          [-1, 384, 19, 19]               0\n",
      "           Conv2d-94          [-1, 384, 19, 19]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 19, 19]             768\n",
      "            ReLU6-96          [-1, 384, 19, 19]               0\n",
      "           Conv2d-97           [-1, 96, 19, 19]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 19, 19]             192\n",
      " InvertedResidual-99           [-1, 96, 19, 19]               0\n",
      "          Conv2d-100          [-1, 576, 19, 19]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 19, 19]           1,152\n",
      "           ReLU6-102          [-1, 576, 19, 19]               0\n",
      "          Conv2d-103          [-1, 576, 19, 19]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 19, 19]           1,152\n",
      "           ReLU6-105          [-1, 576, 19, 19]               0\n",
      "          Conv2d-106           [-1, 96, 19, 19]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 19, 19]             192\n",
      "InvertedResidual-108           [-1, 96, 19, 19]               0\n",
      "          Conv2d-109          [-1, 576, 19, 19]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 19, 19]           1,152\n",
      "           ReLU6-111          [-1, 576, 19, 19]               0\n",
      "          Conv2d-112          [-1, 576, 19, 19]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 19, 19]           1,152\n",
      "           ReLU6-114          [-1, 576, 19, 19]               0\n",
      "          Conv2d-115           [-1, 96, 19, 19]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 19, 19]             192\n",
      "InvertedResidual-117           [-1, 96, 19, 19]               0\n",
      "          Conv2d-118          [-1, 576, 19, 19]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 19, 19]           1,152\n",
      "           ReLU6-120          [-1, 576, 19, 19]               0\n",
      "          Conv2d-121          [-1, 576, 10, 10]           5,184\n",
      "     BatchNorm2d-122          [-1, 576, 10, 10]           1,152\n",
      "           ReLU6-123          [-1, 576, 10, 10]               0\n",
      "          Conv2d-124          [-1, 160, 10, 10]          92,160\n",
      "     BatchNorm2d-125          [-1, 160, 10, 10]             320\n",
      "InvertedResidual-126          [-1, 160, 10, 10]               0\n",
      "          Conv2d-127          [-1, 960, 10, 10]         153,600\n",
      "     BatchNorm2d-128          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-129          [-1, 960, 10, 10]               0\n",
      "          Conv2d-130          [-1, 960, 10, 10]           8,640\n",
      "     BatchNorm2d-131          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-132          [-1, 960, 10, 10]               0\n",
      "          Conv2d-133          [-1, 160, 10, 10]         153,600\n",
      "     BatchNorm2d-134          [-1, 160, 10, 10]             320\n",
      "InvertedResidual-135          [-1, 160, 10, 10]               0\n",
      "          Conv2d-136          [-1, 960, 10, 10]         153,600\n",
      "     BatchNorm2d-137          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-138          [-1, 960, 10, 10]               0\n",
      "          Conv2d-139          [-1, 960, 10, 10]           8,640\n",
      "     BatchNorm2d-140          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-141          [-1, 960, 10, 10]               0\n",
      "          Conv2d-142          [-1, 160, 10, 10]         153,600\n",
      "     BatchNorm2d-143          [-1, 160, 10, 10]             320\n",
      "InvertedResidual-144          [-1, 160, 10, 10]               0\n",
      "          Conv2d-145          [-1, 960, 10, 10]         153,600\n",
      "     BatchNorm2d-146          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-147          [-1, 960, 10, 10]               0\n",
      "          Conv2d-148          [-1, 960, 10, 10]           8,640\n",
      "     BatchNorm2d-149          [-1, 960, 10, 10]           1,920\n",
      "           ReLU6-150          [-1, 960, 10, 10]               0\n",
      "          Conv2d-151          [-1, 320, 10, 10]         307,200\n",
      "     BatchNorm2d-152          [-1, 320, 10, 10]             640\n",
      "InvertedResidual-153          [-1, 320, 10, 10]               0\n",
      "          Conv2d-154         [-1, 1280, 10, 10]         409,600\n",
      "     BatchNorm2d-155         [-1, 1280, 10, 10]           2,560\n",
      "           ReLU6-156         [-1, 1280, 10, 10]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                   [-1, 30]          38,430\n",
      "     MobileNetV2-159                   [-1, 30]               0\n",
      "================================================================\n",
      "Total params: 2,262,302\n",
      "Trainable params: 38,430\n",
      "Non-trainable params: 2,223,872\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.03\n",
      "Forward/backward pass size (MB): 278.99\n",
      "Params size (MB): 8.63\n",
      "Estimated Total Size (MB): 288.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model_mobile,input_size=(3,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_mobile.state_dict(),\"models/mobel_mobile15epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deneme = MobileNetV2Transfer(30).to(device)\n",
    "model_deneme.load_state_dict(torch.load(\"models/mobel_mobile15epochs.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.eval()\n",
    "\n",
    "scripted_model = torch.jit.script(model_deneme) \n",
    "scripted_model.save(\"models/model_native.pt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
